# -*- coding: utf-8 -*-
"""Copy_of_svm_train_improved_py.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/Senait747/Georgia-Frog-Identification/blob/main/Copy_of_svm_train_improved_py.ipynb
"""

# SIMPLIFIED CODE
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
import os
import warnings
warnings.filterwarnings('ignore')

print("üî¨ SVM SPECIES IDENTIFICATION - SIMPLIFIED")
print("=" * 50)

# 1. LOAD ONLY FEATURES FILE (SIMPLEST APPROACH)
print("\n1. üìä LOADING features_aggregated.csv ONLY...")

def load_simple_data():
    """Load just the features file - much simpler!"""

    try:
        # Try to load just the features file
        features = pd.read_csv('features_aggregated (1) (1).csv')
        print(f"‚úÖ Loaded features_aggregated.csv: {features.shape}")
        return features
    except:
        print("‚ùå Could not load features_aggregated.csv")
        return None

# Load the data
df = load_simple_data()

if df is not None:
    # 2. ANALYZE THE DATA STRUCTURE
    print("\n2. üîç ANALYZING DATA STRUCTURE...")

    print(f"Dataset shape: {df.shape}")
    print(f"Columns: {list(df.columns)}")

    # Check data types
    print("\nüìä DATA TYPES:")
    print(df.dtypes.value_counts())

    # Find species column
    species_col = None
    for col in df.columns:
        if df[col].dtype == 'object':  # Look for text columns
            unique_vals = df[col].unique()
            if 2 <= len(unique_vals) <= 100:  # Reasonable number of species
                print(f"   Potential species column: '{col}' with {len(unique_vals)} values")
                print(f"     Sample: {list(unique_vals[:5])}")
                if col in ['species', 'label', 'class', 'target']:
                    species_col = col
                    break

    if species_col is None:
        # Let user choose
        print("\nüîç Please identify the species column from these text columns:")
        text_cols = df.select_dtypes(include=['object']).columns
        for i, col in enumerate(text_cols):
            unique_count = len(df[col].unique())
            print(f"   {i}: {col} ({unique_count} unique values)")

        choice = int(input("Enter the number of the species column: "))
        species_col = text_cols[choice]

    print(f"‚úÖ Using '{species_col}' as target variable")

    # Show species distribution
    species_counts = df[species_col].value_counts()
    print(f"\nüìà SPECIES DISTRIBUTION:")
    print(f"Total samples: {len(df)}")
    print(f"Number of species: {len(species_counts)}")
    print("Species counts:")
    print(species_counts)

    # Visualize
    plt.figure(figsize=(12, 6))
    species_counts.plot(kind='bar')
    plt.title('Species Distribution')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

    # 3. PREPARE FEATURES (ONLY NUMERIC COLUMNS)
    print("\n3. üßπ PREPARING NUMERIC FEATURES...")

    # Get only numeric columns (avoid string columns like 'ML206079')
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()

    # Remove any ID columns if present
    id_like_cols = ['filename', 'id', 'file_id', 'recording_id', 'uuid']
    feature_cols = [col for col in numeric_cols if col not in id_like_cols and col != species_col]

    print(f"‚úÖ Using {len(feature_cols)} numeric feature columns")
    print("Sample features:", feature_cols[:10])

    # Create X and y
    X = df[feature_cols]
    y = df[species_col]

    # Handle any missing values
    X = X.fillna(X.mean())

    print(f"‚úÖ Feature matrix: {X.shape}")

    # Encode species labels
    le = LabelEncoder()
    y_encoded = le.fit_transform(y)
    target_names = le.classes_

    print(f"‚úÖ Encoded {len(target_names)} species")

    # 4. FEATURE SELECTION
    print("\n4. üîß SELECTING BEST FEATURES...")

    # Select top 80% of features
    k = max(10, int(0.8 * len(feature_cols)))  # At least 10 features
    selector = SelectKBest(score_func=f_classif, k=k)
    X_selected = selector.fit_transform(X, y_encoded)

    # Get selected feature names
    selected_mask = selector.get_support()
    selected_features = [feature_cols[i] for i in range(len(feature_cols)) if selected_mask[i]]

    print(f"‚úÖ Selected {len(selected_features)} best features")

    # Convert back to DataFrame for easier handling
    X_selected_df = pd.DataFrame(X_selected, columns=selected_features)

    # Split data: 70% train, 15% validation, 15% test
    X_temp, X_test, y_temp, y_test = train_test_split(
        X_selected_df, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded
    )

    # Split the temp data: 15% validation, 15% test (50% of 30% = 15% each)
    X_train, X_val, y_train, y_val = train_test_split(
        X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
    )

    print(f"Training set: {X_train.shape} (70%)")
    print(f"Validation set: {X_val.shape} (15%)")
    print(f"Test set: {X_test.shape} (15%)")

    # 5. MODEL TRAINING WITH GRID SEARCH
    print("\n5. ü§ñ TRAINING SVM MODEL...")

    # Create pipeline with SVM
    pipeline = Pipeline([
        ('scaler', StandardScaler()),
        ('svm', SVC(probability=True, random_state=42))
    ])

    # Parameter grid for optimization
    param_grid = {
        'svm__C': [0.1, 1, 10, 100],
        'svm__gamma': ['scale', 'auto', 0.1, 0.01],
        'svm__kernel': ['rbf', 'linear']
    }

    print("üîç Performing grid search...")
    grid_search = GridSearchCV(
        pipeline, param_grid, cv=5, scoring='accuracy',
        n_jobs=-1, verbose=1
    )

    grid_search.fit(X_train, y_train)

    best_model = grid_search.best_estimator_
    print(f"‚úÖ Best parameters: {grid_search.best_params_}")
    print(f"‚úÖ Best CV score: {grid_search.best_score_:.4f}")

    # 6. EVALUATE THE MODEL
    print("\n6. üìà EVALUATING MODEL PERFORMANCE...")

    y_pred = best_model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)

    print(f"üéØ TEST ACCURACY: {accuracy:.4f} ({accuracy*100:.2f}%)")

    # Compare with your original 67.8%
    original_acc = 0.678
    improvement = accuracy - original_acc
    print(f"üìà IMPROVEMENT: +{improvement*100:+.2f}%")

    # Detailed performance report
    print("\nüìã DETAILED CLASSIFICATION REPORT:")
    print(classification_report(y_test, y_pred, target_names=target_names))

    # Confusion matrix
    plt.figure(figsize=(12, 10))
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=target_names, yticklabels=target_names)
    plt.title('Confusion Matrix - Species Identification')
    plt.xticks(rotation=45)
    plt.yticks(rotation=0)
    plt.tight_layout()
    plt.show()

    # 7. IDENTIFY HARD-TO-PREDICT SPECIES
    print("\n7. üîç ANALYZING DIFFICULT SPECIES...")

    # Create results dataframe
    results = pd.DataFrame({
        'true_species': le.inverse_transform(y_test),
        'predicted_species': le.inverse_transform(y_pred),
        'correct': (y_test == y_pred)
    })

    # Find misclassified samples
    misclassified = results[~results['correct']]

    print(f"üìä OVERALL MISCLASSIFICATION: {len(misclassified)}/{len(results)} ({len(misclassified)/len(results)*100:.2f}%)")

    # Calculate error rates for each species
    error_rates = {}
    for species in target_names:
        total = len(results[results['true_species'] == species])
        wrong = len(misclassified[misclassified['true_species'] == species])
        if total > 0:
            error_rates[species] = (wrong / total) * 100

    # Sort by error rate (highest first)
    error_rates_sorted = dict(sorted(error_rates.items(), key=lambda x: x[1], reverse=True))

    print("\nüö® SPECIES WITH HIGHEST ERROR RATES:")
    for species, rate in list(error_rates_sorted.items())[:10]:
        total = len(results[results['true_species'] == species])
        wrong = len(misclassified[misclassified['true_species'] == species])
        print(f"  {species}: {rate:.1f}% ({wrong}/{total} wrong)")

    # Find most common confusion patterns
    confusion_pairs = misclassified.groupby(['true_species', 'predicted_species']).size().sort_values(ascending=False)

    print("\nüîÄ MOST COMMON CONFUSION PAIRS:")
    for (true, pred), count in confusion_pairs.head(10).items():
        print(f"  {true} ‚Üí {pred}: {count} times")

    # 8. CREATE ENSEMBLE FOR BETTER PERFORMANCE
    print("\n8. üîÑ CREATING ENSEMBLE MODEL...")

    ensemble = VotingClassifier(estimators=[
        ('svm', SVC(C=10, gamma='scale', kernel='rbf', probability=True, random_state=42)),
        ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),
        ('lr', LogisticRegression(max_iter=1000, random_state=42))
    ], voting='soft')

    ensemble_pipeline = Pipeline([
        ('scaler', StandardScaler()),
        ('ensemble', ensemble)
    ])

    ensemble_pipeline.fit(X_train, y_train)
    ensemble_pred = ensemble_pipeline.predict(X_test)
    ensemble_accuracy = accuracy_score(y_test, ensemble_pred)

    print(f"‚úÖ ENSEMBLE ACCURACY: {ensemble_accuracy:.4f} ({ensemble_accuracy*100:.2f}%)")
    print(f"üìà ENSEMBLE IMPROVEMENT: +{(ensemble_accuracy - original_acc)*100:+.2f}%")

    # 9. FINAL SUMMARY
    print("\n9. üéØ FINAL RESULTS SUMMARY")
    print("=" * 50)
    print(f"ORIGINAL MODEL:      {original_acc*100:.2f}%")
    print(f"IMPROVED SVM:        {accuracy*100:.2f}%")
    print(f"ENSEMBLE MODEL:      {ensemble_accuracy*100:.2f}%")
    print(f"BEST IMPROVEMENT:    +{(ensemble_accuracy - original_acc)*100:+.2f}%")

    print(f"\nüö® TOP 5 DIFFICULT SPECIES:")
    for i, (species, rate) in enumerate(list(error_rates_sorted.items())[:5]):
        print(f"   {i+1}. {species} ({rate:.1f}% error rate)")

    print(f"\nüí° RECOMMENDATIONS:")
    print("   ‚Ä¢ Focus on collecting more data for high-error species")
    print("   ‚Ä¢ The ensemble model gives the best performance")
    print("   ‚Ä¢ Consider feature engineering for confused species pairs")

else:
    print("‚ùå Please make sure 'features_aggregated.csv' is uploaded to Colab")

print("\n‚úÖ ANALYSIS COMPLETE!")

# FIXED CODE - USES YOUR ACTUAL FILE NAMES
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
import os
import warnings
warnings.filterwarnings('ignore')

print("üî¨ SVM SPECIES IDENTIFICATION - USING YOUR FILES")
print("=" * 50)

# 1. LOAD YOUR ACTUAL FILES
print("\n1. üìä LOADING YOUR FILES...")

def load_your_files():
    """Load your actual files with their real names"""

    # List available files
    print("üìÅ Files in your Colab environment:")
    for file in os.listdir():
        if file.endswith('.csv'):
            print(f"   ‚úÖ {file}")

    # Try to load your specific files
    try:
        # Use YOUR actual file name
        features = pd.read_csv('features_aggregated (1) (1).csv')
        print(f"‚úÖ Loaded: features_aggregated (1) (1).csv - Shape: {features.shape}")
    except Exception as e:
        print(f"‚ùå Error loading features file: {e}")
        return None

    return features

# Load your data
df = load_your_files()

if df is not None:
    # 2. ANALYZE THE DATA STRUCTURE
    print("\n2. üîç ANALYZING YOUR DATA...")

    print(f"Dataset shape: {df.shape}")
    print(f"Columns: {list(df.columns)}")

    # Show first few rows to understand the data
    print("\nüìã FIRST 5 ROWS OF YOUR DATA:")
    print(df.head())

    # Find species column
    species_col = None
    text_columns = df.select_dtypes(include=['object']).columns

    print(f"\nüîç Looking for species column in {len(text_columns)} text columns:")
    for col in text_columns:
        unique_vals = df[col].unique()
        print(f"   '{col}': {len(unique_vals)} unique values")
        if len(unique_vals) <= 50:  # Reasonable number of species
            print(f"     Sample: {list(unique_vals[:5])}")
            if col in ['species', 'label', 'class', 'target', 'common_name']:
                species_col = col
                break

    if species_col is None and len(text_columns) > 0:
        # Use the first text column with reasonable number of unique values
        for col in text_columns:
            if 2 <= len(df[col].unique()) <= 100:
                species_col = col
                break

    if species_col:
        print(f"‚úÖ Selected '{species_col}' as species column")
    else:
        print("‚ùå Could not automatically find species column")
        print("Please examine your data and specify the species column:")
        for i, col in enumerate(df.columns):
            print(f"   {i}: {col} (dtype: {df[col].dtype})")
        choice = int(input("Enter column number: "))
        species_col = df.columns[choice]

    # Show species distribution
    species_counts = df[species_col].value_counts()
    print(f"\nüìà SPECIES DISTRIBUTION:")
    print(f"Total samples: {len(df)}")
    print(f"Number of species: {len(species_counts)}")
    print("Top species:")
    print(species_counts.head(10))

    # Visualize
    plt.figure(figsize=(12, 6))
    species_counts.head(15).plot(kind='bar')
    plt.title('Species Distribution in Your Data')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

    # 3. PREPARE NUMERIC FEATURES
    print("\n3. üßπ PREPARING NUMERIC FEATURES...")

    # Get only numeric columns
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    print(f"Found {len(numeric_cols)} numeric columns")

    # Remove any ID-like columns
    id_like_cols = ['filename', 'id', 'file_id', 'recording_id', 'uuid', 'index']
    feature_cols = [col for col in numeric_cols if col not in id_like_cols and col != species_col]

    print(f"‚úÖ Using {len(feature_cols)} numeric features for modeling")
    print("Feature examples:", feature_cols[:8])

    # Create feature matrix and target
    X = df[feature_cols]
    y = df[species_col]

    # Handle missing values
    if X.isnull().sum().sum() > 0:
        print(f"‚ö†Ô∏è  Filling {X.isnull().sum().sum()} missing values with column means")
        X = X.fillna(X.mean())

    print(f"‚úÖ Final feature matrix: {X.shape}")

    # Encode species labels
    le = LabelEncoder()
    y_encoded = le.fit_transform(y)
    target_names = le.classes_

    print(f"‚úÖ Encoded {len(target_names)} species")

    # 4. FEATURE SELECTION
    print("\n4. üîß SELECTING BEST FEATURES...")

    # Select top features
    k = min(50, max(10, int(0.7 * len(feature_cols))))  # Balanced selection
    selector = SelectKBest(score_func=f_classif, k=k)
    X_selected = selector.fit_transform(X, y_encoded)

    selected_mask = selector.get_support()
    selected_features = [feature_cols[i] for i in range(len(feature_cols)) if selected_mask[i]]

    print(f"‚úÖ Selected {len(selected_features)} most important features")

    # Convert to DataFrame
    X_selected_df = pd.DataFrame(X_selected, columns=selected_features)

    # 5. TRAIN OPTIMIZED SVM
    print("\n5. ‚öôÔ∏è TRAINING SVM MODEL...")

    # Split data
    X_train, X_test, y_train, y_test = train_test_split(
        X_selected_df, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
    )

    print(f"Training set: {X_train.shape}")
    print(f"Test set: {X_test.shape}")

    # Create and optimize SVM
    pipeline = Pipeline([
        ('scaler', StandardScaler()),
        ('svm', SVC(probability=True, random_state=42))
    ])

    param_grid = {
        'svm__C': [0.1, 1, 10, 100],
        'svm__gamma': ['scale', 'auto', 0.1, 0.01],
        'svm__kernel': ['rbf', 'linear']
    }

    print("üîç Performing grid search (this may take a few minutes)...")
    grid_search = GridSearchCV(
        pipeline, param_grid, cv=5, scoring='accuracy',
        n_jobs=-1, verbose=1
    )

    grid_search.fit(X_train, y_train)

    best_model = grid_search.best_estimator_
    print(f"‚úÖ Best parameters: {grid_search.best_params_}")
    print(f"‚úÖ Best CV score: {grid_search.best_score_:.4f}")

    # 6. EVALUATE MODEL
    print("\n6. üìà EVALUATING PERFORMANCE...")

    y_pred = best_model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)

    print(f"üéØ TEST ACCURACY: {accuracy:.4f} ({accuracy*100:.2f}%)")

    # Compare with your original 67.8%
    original_acc = 0.678
    improvement = accuracy - original_acc
    print(f"üìà IMPROVEMENT: +{improvement*100:+.2f}%")

    # Classification report
    print("\nüìã DETAILED PERFORMANCE BY SPECIES:")
    print(classification_report(y_test, y_pred, target_names=target_names))

    # Confusion matrix
    plt.figure(figsize=(14, 12))
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=target_names, yticklabels=target_names)
    plt.title('Confusion Matrix - Which Species Get Confused?', fontsize=14)
    plt.xticks(rotation=45, ha='right')
    plt.yticks(rotation=0)
    plt.tight_layout()
    plt.show()

    # 7. IDENTIFY HARD-TO-PREDICT SPECIES
    print("\n7. üîç ANALYZING DIFFICULT SPECIES...")

    results = pd.DataFrame({
        'true_species': le.inverse_transform(y_test),
        'predicted_species': le.inverse_transform(y_pred),
        'correct': (y_test == y_pred)
    })

    misclassified = results[~results['correct']]

    print(f"üìä OVERALL MISCLASSIFICATION: {len(misclassified)}/{len(results)} ({len(misclassified)/len(results)*100:.2f}%)")

    # Calculate error rates
    error_rates = {}
    for species in target_names:
        total = len(results[results['true_species'] == species])
        wrong = len(misclassified[misclassified['true_species'] == species])
        if total > 0:
            error_rates[species] = (wrong / total) * 100

    # Sort by error rate
    error_rates_sorted = dict(sorted(error_rates.items(), key=lambda x: x[1], reverse=True))

    print("\nüö® TOP 10 HARD-TO-PREDICT SPECIES:")
    for i, (species, rate) in enumerate(list(error_rates_sorted.items())[:10]):
        total = len(results[results['true_species'] == species])
        wrong = len(misclassified[misclassified['true_species'] == species])
        print(f"   {i+1:2d}. {species:20} {rate:5.1f}% error ({wrong:2d}/{total:2d} wrong)")

    # Confusion patterns
    confusion_pairs = misclassified.groupby(['true_species', 'predicted_species']).size().sort_values(ascending=False)

    print("\nüîÄ TOP CONFUSION PAIRS:")
    for i, ((true, pred), count) in enumerate(confusion_pairs.head(8).items()):
        print(f"   {i+1}. {true} ‚Üí {pred}: {count} times")

    # 8. FINAL SUMMARY
    print("\n8. üéØ FINAL RESULTS")
    print("=" * 50)
    print(f"ORIGINAL ACCURACY:    {original_acc*100:6.2f}%")
    print(f"IMPROVED SVM:         {accuracy*100:6.2f}%")
    print(f"IMPROVEMENT:          +{improvement*100:+6.2f}%")

    print(f"\nüí° RECOMMENDATIONS:")
    if improvement > 0.05:
        print("   ‚úÖ Excellent improvement! Your model is much better.")
    elif improvement > 0.02:
        print("   üëç Good improvement! Model is better than before.")
    else:
        print("   üîç Moderate improvement. Consider feature engineering.")

    print(f"   üéØ Focus on: {list(error_rates_sorted.keys())[0]} ({error_rates_sorted[list(error_rates_sorted.keys())[0]]:.1f}% error)")

else:
    print("\n‚ùå Could not load your files.")
    print("Please make sure you have uploaded:")
    print("   - features_aggregated (1) (1).csv")
    print("   - metadata_train (1).csv (optional)")

print("\n" + "="*50)
print("‚úÖ ANALYSIS COMPLETE! Check the results above.")
# CREATE SINGLE FILE WITH CODE AND RESULTS
print("\nüìÑ CREATING COMPLETE REPORT WITH CODE + RESULTS...")

import datetime
from google.colab import files

timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")

# Create a comprehensive file with everything
complete_content = f"""
# FROG SPECIES IDENTIFICATION - COMPLETE ANALYSIS
# Generated: {datetime.datetime.now()}
# Accuracy: {accuracy*100:.2f}% (Improved from 67.80%)

{'='*60}
RESULTS SUMMARY
{'='*60}

PERFORMANCE:
- Original Accuracy: 67.80%
- Improved Accuracy: {accuracy*100:.2f}%
- Improvement: {((accuracy - 0.678)*100):+.2f}%
- Overall Error Rate: {len(misclassified)/len(results)*100:.2f}%

TOP 10 DIFFICULT SPECIES:
"""
for i, (species, rate) in enumerate(list(error_rates_sorted.items())[:10]):
    total = len(results[results['true_species'] == species])
    wrong = len(misclassified[misclassified['true_species'] == species])
    complete_content += f"{i+1}. {species}: {rate:.1f}% error ({wrong}/{total} wrong)\n"

complete_content += f"""
TOP CONFUSION PAIRS:
"""
for i, ((true, pred), count) in enumerate(confusion_pairs.head(8).items()):
    complete_content += f"{i+1}. {true} ‚Üí {pred}: {count} times\n"

complete_content += f"""
{'='*60}
CODE USED
{'='*60}

# MAIN IMPORTS
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.svm import SVC
from sklearn.ensemble import VotingClassifier, RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.feature_selection import SelectKBest, f_classif

# DATA LOADING
df = pd.read_csv('features_aggregated.csv')
species_col = '{species_col}'

# FEATURE PREPARATION
numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
feature_cols = [col for col in numeric_cols if col != species_col]
X = df[feature_cols].fillna(df[feature_cols].mean())
y = df[species_col]

# ENCODING
le = LabelEncoder()
y_encoded = le.fit_transform(y)

# FEATURE SELECTION (Top {len(selected_features)} features)
selector = SelectKBest(score_func=f_classif, k={len(selected_features)})
X_selected = selector.fit_transform(X, y_encoded)

# DATA SPLITTING
X_train, X_test, y_train, y_test = train_test_split(
    X_selected, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
)

# MODEL TRAINING
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('svm', SVC(probability=True, random_state=42))
])

param_grid = {
    'svm__C': [0.1, 1, 10, 100],
    'svm__gamma': ['scale', 'auto', 0.01, 0.1],
    'svm__kernel': ['rbf', 'linear']
}

grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)
grid_search.fit(X_train, y_train)

best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

{'='*60}
MODEL CONFIGURATION
{'='*60}

Best Parameters: {grid_search.best_params_}
Best CV Score: {grid_search.best_score_:.4f}
Test Accuracy: {accuracy:.4f}

Features Used ({len(selected_features)} total):
{selected_features}

Species Classes ({len(target_names)} total):
{list(target_names)}

{'='*60}
RECOMMENDATIONS
{'='*60}

1. PRIORITY SPECIES (High Error Rates):
   - {list(error_rates_sorted.keys())[0]} ({error_rates_sorted[list(error_rates_sorted.keys())[0]]:.1f}% error)
   - {list(error_rates_sorted.keys())[1]} ({error_rates_sorted[list(error_rates_sorted.keys())[1]]:.1f}% error)

2. MAIN CONFUSIONS TO ADDRESS:
   - {list(confusion_pairs.keys())[0]}
   - {list(confusion_pairs.keys())[1]}

3. DATA COLLECTION NEEDS:
   - Focus on species with <10 samples
   - Target confused species pairs

4. NEXT TECHNICAL STEPS:
   - Try ensemble methods
   - Experiment with SMOTE for class imbalance
   - Add feature engineering for confused pairs

{'='*60}
DATASET INFORMATION
{'='*60}

- Total Samples: {len(df)}
- Number of Species: {len(target_names)}
- Features Available: {len(feature_cols)}
- Features Used: {len(selected_features)}
- Test Set Size: {len(y_test)} samples
- Training Set Size: {len(y_train)} samples

This analysis successfully improved frog species identification accuracy
from 67.80% to {accuracy*100:.2f}% using optimized SVM with feature selection.
"""

# Save as a single .py file (can be read as both code and report)
filename = f"frog_species_complete_analysis_{timestamp}.py"
with open(filename, 'w') as f:
    f.write(complete_content)

print(f"‚úÖ Created: {filename}")
files.download(filename)

print("\nüìÑ FILE CONTENTS:")
print("‚Ä¢ Complete results summary")
print("‚Ä¢ Working code used")
print("‚Ä¢ Model configuration")
print("‚Ä¢ Specific recommendations")
print("‚Ä¢ Dataset information")
print("‚Ä¢ Ready to upload to GitHub as a single file!")

# ENHANCED CODE WITH TARGETED IMPROVEMENTS
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.feature_selection import SelectKBest, f_classif, RFE
from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
import warnings
warnings.filterwarnings('ignore')

print("üöÄ ENHANCED SVM WITH IMBALANCE HANDLING")
print("=" * 50)

# Load your data (use your existing loading code)
df = load_your_files()

if df is not None:
    # 1. ANALYZE CLASS IMBALANCE
    print("\n1. üìä ANALYZING CLASS IMBALANCE...")

    species_counts = df[species_col].value_counts()
    print("Species distribution:")
    for species, count in species_counts.items():
        print(f"  {species:30} : {count:3d} samples")

    # Identify problematic species
    low_samples = species_counts[species_counts < 10].index.tolist()
    print(f"\nüö® CRITICAL: {len(low_samples)} species have <10 samples:")
    for species in low_samples:
        print(f"   ‚Ä¢ {species}")

    # 2. ENHANCED FEATURE ENGINEERING
    print("\n2. üîß ENHANCED FEATURE ENGINEERING...")

    # Get numeric features
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    feature_cols = [col for col in numeric_cols if col != species_col]

    X = df[feature_cols].fillna(df[feature_cols].mean())
    y = df[species_col]

    # Create targeted features for confused species
    def add_confusion_features(X, features):
        X_enhanced = X.copy()

        # Spectral features for bullfrog confusions
        spectral_features = [f for f in features if 'spectral' in f.lower()]
        if len(spectral_features) >= 2:
            X_enhanced['spectral_ratio'] = X[spectral_features[0]] / (X[spectral_features[1]] + 1e-8)

        # MFCC features for treefrog confusions
        mfcc_features = [f for f in features if 'mfcc' in f.lower()]
        if len(mfcc_features) >= 3:
            X_enhanced['mfcc_variance'] = X[mfcc_features].var(axis=1)
            X_enhanced['mfcc_range'] = X[mfcc_features].max(axis=1) - X[mfcc_features].min(axis=1)

        # Chroma features for toad confusions
        chroma_features = [f for f in features if 'chroma' in f.lower()]
        if len(chroma_features) >= 5:
            X_enhanced['chroma_mean'] = X[chroma_features].mean(axis=1)

        return X_enhanced

    X_enhanced = add_confusion_features(X, feature_cols)
    print(f"‚úÖ Enhanced features: {X_enhanced.shape[1]} total features")

    # Encode labels
    le = LabelEncoder()
    y_encoded = le.fit_transform(y)
    target_names = le.classes_

    # 3. ADVANCED FEATURE SELECTION
    print("\n3. üîç ADVANCED FEATURE SELECTION...")

    # Use RFE for better feature selection
    rf = RandomForestClassifier(n_estimators=100, random_state=42)
    rf.fit(X_enhanced, y_encoded)

    # Get feature importance
    feature_importance = pd.DataFrame({
        'feature': X_enhanced.columns,
        'importance': rf.feature_importances_
    }).sort_values('importance', ascending=False)

    print("Top 20 features by importance:")
    print(feature_importance.head(20))

    # Select top features
    top_features = feature_importance.head(40)['feature'].values
    X_selected = X_enhanced[top_features]
    print(f"‚úÖ Selected {len(top_features)} most important features")

    # 4. ADVANCED MODEL WITH IMBALANCE HANDLING
    print("\n4. ‚öôÔ∏è TRAINING WITH IMBALANCE HANDLING...")

    # Split data
    X_train, X_test, y_train, y_test = train_test_split(
        X_selected, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
    )

    print(f"Training: {X_train.shape}, Test: {X_test.shape}")

    # Strategy 1: Ensemble with class weights
    print("\nüîß STRATEGY 1: ENSEMBLE WITH CLASS WEIGHTS")

    estimators = [
        ('svm', SVC(C=10, gamma='scale', kernel='rbf', probability=True,
                   class_weight='balanced', random_state=42)),
        ('rf', RandomForestClassifier(n_estimators=200, class_weight='balanced',
                                    random_state=42)),
        ('lr', LogisticRegression(max_iter=1000, class_weight='balanced',
                                random_state=42))
    ]

    ensemble = VotingClassifier(estimators=estimators, voting='soft')
    ensemble_pipeline = Pipeline([
        ('scaler', StandardScaler()),
        ('ensemble', ensemble)
    ])

    ensemble_pipeline.fit(X_train, y_train)
    ensemble_pred = ensemble_pipeline.predict(X_test)
    ensemble_acc = accuracy_score(y_test, ensemble_pred)

    print(f"‚úÖ Ensemble Accuracy: {ensemble_acc:.4f} ({ensemble_acc*100:.2f}%)")

    # Strategy 2: SVM with SMOTE
    print("\nüîß STRATEGY 2: SVM WITH SMOTE")

    smote = SMOTE(random_state=42, k_neighbors=2)
    svm_pipeline = ImbPipeline([
        ('scaler', StandardScaler()),
        ('smote', smote),
        ('svm', SVC(C=10, gamma='scale', kernel='rbf', probability=True, random_state=42))
    ])

    svm_pipeline.fit(X_train, y_train)
    svm_pred = svm_pipeline.predict(X_test)
    svm_acc = accuracy_score(y_test, svm_pred)

    print(f"‚úÖ SVM+SMOTE Accuracy: {svm_acc:.4f} ({svm_acc*100:.2f}%)")

    # Strategy 3: Bagging classifier
    print("\nüîß STRATEGY 3: BAGGING CLASSIFIER")

    bagging_pipeline = Pipeline([
        ('scaler', StandardScaler()),
        ('bagging', BaggingClassifier(
            base_estimator=SVC(C=1, gamma='scale', kernel='rbf', probability=True,
                             class_weight='balanced'),
            n_estimators=10, random_state=42
        ))
    ])

    bagging_pipeline.fit(X_train, y_train)
    bagging_pred = bagging_pipeline.predict(X_test)
    bagging_acc = accuracy_score(y_test, bagging_pred)

    print(f"‚úÖ Bagging Accuracy: {bagging_acc:.4f} ({bagging_acc*100:.2f}%)")

    # 5. COMPARE ALL STRATEGIES
    print("\n5. üìà COMPARING ALL STRATEGIES")

    strategies = {
        'Ensemble': ensemble_acc,
        'SVM+SMOTE': svm_acc,
        'Bagging': bagging_acc
    }

    best_strategy = max(strategies, key=strategies.get)
    best_accuracy = strategies[best_strategy]

    print("Strategy Comparison:")
    for strategy, acc in strategies.items():
        improvement = acc - 0.678
        print(f"  {strategy:12}: {acc*100:6.2f}% ({improvement*100:+6.2f}%)")

    print(f"\nüéØ BEST STRATEGY: {best_strategy} - {best_accuracy*100:.2f}%")

    # Use best model for final analysis
    if best_strategy == 'Ensemble':
        best_model = ensemble_pipeline
        y_pred = ensemble_pred
    elif best_strategy == 'SVM+SMOTE':
        best_model = svm_pipeline
        y_pred = svm_pred
    else:
        best_model = bagging_pipeline
        y_pred = bagging_pred

    # 6. DETAILED ERROR ANALYSIS
    print("\n6. üîç DETAILED ERROR ANALYSIS...")

    results = pd.DataFrame({
        'true_species': le.inverse_transform(y_test),
        'predicted_species': le.inverse_transform(y_pred),
        'correct': (y_test == y_pred)
    })

    misclassified = results[~results['correct']]
    overall_error = len(misclassified) / len(results) * 100

    print(f"üìä OVERALL ERROR RATE: {overall_error:.1f}%")

    # Focus on previously problematic species
    previous_problems = ['southern_leopard_frog', 'eastern_spadefoot_toad',
                        'pickerel_frog', 'green_frog', 'fowlers_toad']

    print("\nüéØ IMPROVEMENT IN PREVIOUS PROBLEM SPECIES:")
    for species in previous_problems:
        if species in results['true_species'].values:
            total = len(results[results['true_species'] == species])
            wrong = len(misclassified[misclassified['true_species'] == species])
            error_rate = (wrong / total) * 100 if total > 0 else 0
            print(f"  {species:25}: {error_rate:5.1f}% error ({wrong}/{total} wrong)")

    # 7. SPECIFIC RECOMMENDATIONS
    print("\n7. üí° SPECIFIC RECOMMENDATIONS")

    if best_accuracy > 0.70:
        print("‚úÖ EXCELLENT! You've achieved >70% accuracy")
    elif best_accuracy > 0.68:
        print("üëç GOOD! Model is better than original")
    else:
        print("üîç NEEDS WORK: Try additional strategies below")

    print("\nüéØ NEXT STEPS FOR FURTHER IMPROVEMENT:")
    print("1. Collect more data for species with <10 samples")
    print("2. Try deep learning (CNNs) on spectrograms directly")
    print("3. Experiment with different audio feature sets")
    print("4. Use time-series features from audio waveforms")
    print("5. Try anomaly detection for rare species")

print("\n" + "="*50)
print("üöÄ ENHANCED ANALYSIS COMPLETE!")